{
  "hash": "4996e0c010efb967ff512a61a5e76729",
  "result": {
    "markdown": "---\ntitle: \"Project 1 - NBA Game Outcomes Prediction\"\nauthor: \"Alex Choi\" \ntoc: true\ntoc-location: right\n---\n\n\n## Introduction\nThis project aims to predict NBA game outcomes using historical data from the 2023-2024 season. By analyzing various predictors such as days since last played, home advantage, and team stability, the goal is to develop an effective classification model that accurately forecasts game results.\n\n## Process\nData Pre-processing:  \n\n- Cleaned original dataset containing 25 predictor variables and 2,460 observations.\n- Engineered features: Days Since Last Played, Home Advantage, and Stability.\n- Conducted exploratory data analysis (EDA) to evaluate feature relevance.\n\nModeling and Evaluation:  \n\n- Implemented Quadratic Discriminant Analysis (QDA), Random Forest (RF), and Support Vector Machine (SVM).\n- Split data into 75% training and 25% testing subsets.\n- Compared models based on accuracy, with SVM performing best (71% accuracy).\n\nOptimization: \n\n- Tuned hyperparameters for SVM (optimal parameter C identified as 1).\n- Conducted iterative model refinement by testing feature subsets.\n\n## Outcome\n- Developed a final SVM model predicting NBA game outcomes with **71% accuracy**.\n- Determined that Home Advantage is the most significant predictor, while Days Since Last Played and Stability had minimal impact.\n- Demonstrated effectiveness of a streamlined model using fewer, impactful features for accurate sports outcome prediction.\n\n## Output\nFull Model: \n\n| Model | Training Accuracy | Testing Accuracy |\n|:-----:|:-----------------:|:----------------:|\n| QDA   | 0.55             | 0.55             |\n| RF    | 0.60             | 0.56             |\n| SVM   | 0.59             | 0.54             |\n\nReduced Model With Home Advantage: \n\n| Model | Training Accuracy | Testing Accuracy |\n|:-----:|:-----------------:|:----------------:|\n| QDA   | 0.64             | 0.68             |\n| RF    | 1.00             | 0.68             |\n| SVM   | 0.68             | 0.71             |\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, r2_score, mean_squared_error\n# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n# from sklearn.model_selection import train_test_split\n# from sklearn.linear_model import Lasso, Ridge, LassoCV, RidgeCV, LinearRegression\n# from sklearn.metrics import mean_squared_error\n# from sklearn import svm\n# import numpy as np\n# from sklearn.model_selection import GridSearchCV\n# \n# df['Game Date'] = pd.to_datetime(df['Game Date'])\n# Home = []\n# for i in range(df.shape[0]):\n#     if df.iloc[:, 1][i][4:6]=='vs':\n#         Home.append(1)\n#     if df.iloc[:,1][i][4:6]=='@ ':\n#         Home.append(0)\n# df['home'] = np.array(Home)\n# \n# df.loc[df['W/L'] == 'W', 'W/L'] = 1\n# df.loc[df['W/L'] == 'L', 'W/L'] = 0\n# df.loc[df['FT%']=='-','FT%']=1\n# Features = ['W/L','PTS', 'FGM', 'FGA',\n#         'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%', 'OREB', 'DREB', 'REB',\n#         'AST', 'STL', 'BLK', 'TOV', 'PF', '+/-']\n# \n# for i in Features:\n#   df[i] = df[i].astype(float)\n# \n# def Weighting_fun(L,alpha=0.5):\n#     Res = [np.exp(-alpha * i/5) for i in np.arange(L,0,-1)]\n#     Res /= np.sum(Res)\n#     #print(Res)\n#     return Res\n# def Rati_Error(alpha):\n#   X_all = []\n#   Y_all = []\n#   for i in np.arange(500, df.shape[0]):\n#       Team_1 = df.iloc[i, 0]\n#       Team_2 = df.iloc[i, 1][-3::]\n#       Data_Previous_1 = (df.iloc[0:(i - 1), :][df.iloc[0:(i - 1), 0] == Team_1])\n#       Data_Previous_2 = (df.iloc[0:(i - 1), :][df.iloc[0:(i - 1), 0] == Team_2])\n#       Data_Previous_1 = Data_Previous_1[Data_Previous_1['Game Date'] != df.iloc[i, 2]]\n#       Data_Previous_2 = Data_Previous_2[Data_Previous_2['Game Date'] != df.iloc[i, 2]]\n#       Data_Previous_1_home = np.array(Data_Previous_1[Data_Previous_1['home'] == df.iloc[i, -1]][Features])\n#       Data_Previous_2_home = np.array(Data_Previous_2[Data_Previous_2['home'] == (1 - df.iloc[i, -1])][Features])\n#       W1 = Weighting_fun(Data_Previous_1_home.shape[0], alpha).reshape(-1, 1)\n#       W2 = Weighting_fun(Data_Previous_2_home.shape[0], alpha).reshape(-1, 1)\n#       Data_1 = np.array(Data_Previous_1_home * W1).sum(axis=0)\n#       Data_2 = np.array(Data_Previous_2_home * W2).sum(axis=0)\n#       Diff = (Data_1 - Data_2).tolist() + [df.iloc[i, -1]]\n#       X_all.append(Diff)\n#       Y_all.append(df.iloc[i]['W/L'])\n# \n#   X = np.array(X_all)\n#   y = np.array(Y_all)\n#   N = len(y)\n#   R = 0.75\n#   Int = int(N * R)\n#   X_train, X_test, y_train, y_test = X[0:Int, :], X[Int::, :], y[0:Int], y[Int::]\n#    # Hyperparameter grid\n#   param_grid = {\n#       'C': [0.1, 1, 10],\n#       'gamma': ['scale', 'auto', 0.001, 0.01], #\n#       'kernel': ['rbf', 'linear'],\n#       'random_state' : [42]\n#   }\n# \n#   # Grid search\n#   svc = svm.SVC()\n#   grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, scoring='accuracy')\n#   grid_search.fit(X_train, y_train)\n# \n#   # Best parameters\n#   print(\"Best Parameters:\", grid_search.best_params_)\n#   print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n# \n#   model = svm.SVC(kernel = 'rbf', random_state=42)\n#   print(model.get_params())\n#   model.fit(X_train, y_train)\n#   # Predict using the SVM model\n#   predictions = model.predict(X_test)\n#   accuracy = model.score(X_test, y_test)\n#   train_accuracy = model.score(X_train, y_train)\n#   print(\"Training Accuracy of SVM:\", train_accuracy)\n#   print(\"Testing Accuracy of SVM:\", accuracy)\n#   # Predict using QDA\n#   model = QuadraticDiscriminantAnalysis()\n#   model.fit(X_train, y_train)\n#   # Predict using the QDA model\n#   predictions = model.predict(X_test)\n#   accuracy = model.score(X_test, y_test)\n#   train_accuracy = model.score(X_train, y_train)\n#   print(\"Training Accuracy of QDA:\", train_accuracy)\n#   print(\"Testing Accuracy of QDA:\", accuracy)\n# \n#   # Random forest\n#   model = RandomForestClassifier(n_estimators=100, random_state=42)\n#   model.fit(X_train, y_train)\n#   predictions = model.predict(X_test)\n#   accuracy = model.score(X_test, y_test)\n#   train_accuracy = model.score(X_train, y_train)\n#   print(\"Training Accuracy of Random Forest:\", train_accuracy)\n#   print(\"Testing Accuracy of Random Forest:\", accuracy)\n# \n# Rati_Error(0.05)\n# #for a in np.linspace(0.05,0.4,10):\n# #    Rati_Error(a)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}